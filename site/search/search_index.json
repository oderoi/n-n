{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>nan: Something between tinygrad, PyTorch, karpathy/micrograd, Aten and XLA. Maintained by nano corp.</p>"},{"location":"#progress-and-roadmap-documentation","title":"Progress and Roadmap | Documentation","text":"<p>     A PyTorch like AI Engine from scratch in C programming language </p> <p> Nano is a lightweight, minimalistic high-performance numerical computing library for deep learning written in pure C, designed to bring essential neural network functionalities to low-resource environments. Inspired by projects like minigrad, tinygrad, XLA and PyTorch, Nano aims to provide a foundational toolkit for machine learning enthusiasts, embedded developers, and researchers who want to experiment with deep learning concepts in an efficient, resource-conscious manner. </p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Lightweight Design: Focused on simplicity, Nano provides core deep learning operations without heavy dependencies.</li> <li>Pure C Implementation: Built entirely in C, Nano is designed to be portable and optimized for low-level manipulation.</li> <li>Gradient Calculation: Includes basic automatic differentiation to support backpropagation for training models.</li> <li>Flexible Tensor Operations: Supports fundamental tensor operations required for deep learning.</li> <li>Modular Architecture: Easy to extend or modify, allowing you to explore and experiment with new layers, optimizers, and more.</li> </ul>"},{"location":"#who-is-this-for","title":"Who is This For?","text":"<p>NanoTorch is perfect for those looking to: -  Understand the inner workings of a deep learning library from the ground up. -  Run simple neural networks in resource-limited environments. -  Prototype and test custom ML operations in C.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>This repository includes setup instructions, usage examples, and documentation to help you dive into developing with Nano. Explore the source code to understand how core deep learning concepts like tensor operations and automatic differentiation are implemented.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Nano is open for contributions! Whether you\u2019re fixing bugs, adding new features, or experimenting with optimizations, we welcome your input.</p>"},{"location":"Progress_and_Roadmap/","title":"Progress_and_Roadmap","text":"<p>nan: Something between tinygrad, PyTorch, karpathy/micrograd, Aten and XLA. Maintained by nano corp.</p>"},{"location":"Progress_and_Roadmap/#home-page-documentation","title":"Home Page | Documentation","text":"Progress and Roadmap <p>Nano is designed to provide an accessible, low-level deep learning framework with a focus on simplicity and modularity. Here\u2019s a roadmap showcasing its primary components and future progress milestones:</p>"},{"location":"Progress_and_Roadmap/#core-components","title":"Core Components","text":"<p>\u274c: Not implemented \u2705: Done</p> <ol> <li> <p>Tensor Operations</p> </li> <li> <p>Tensor Creation and Manipulation: Support for tensor creation with various data types (float, double, int) and shapes.</p> </li> </ol> Task Status Tensor \u2705 <ul> <li>Basic Tensor Math:</li> </ul> Operation Formula Status Addition \\(C_{i,j} = A_{i,j} + B_{i,j}\\) \u2705 Subtraction \\(C_{i,j} = A_{i,j} - B_{i,j}\\) \u2705 Maltiplication \\(C_{i,j} = A_{i,j} * B_{i,j}\\) \u2705 Division \\(C_{i,j} = A_{i,j} / B_{i,j}\\) \u2705 Dot_Product \\(\\(C_{i,j} = \\sum_{k=0}^{k-1} \\left(A_{i,k} \\cdot B_{k,j}\\right)\\)\\) \u2705 Exponent \\(C_{i,j} = e^{x_{i,j}}\\) \u2705 Logarithm \\(C_{i,j} = \\log_{10}(X_{i,j})\\) \u274c Power \\(C_{i,j} = (\\mathbf{A}^p){i,j} = (\\mathbf{A}{i,j})^n\\) \u2705 Sum \\(\\mathbf{C}   = \\sum_{i=0}^{i-1}\\(X_{i}\\)\\) \u2705 Transpose \\((\\mathbf{A}^\\top){i,j} = (\\mathbf{A}){j,i}\\) \u2705 Flatten \\(\\text{Flatten}(A_{m,n}) = \\[A_{0,0},\\  A_{0,1}, \\dots\\,\\  A_{m-1, n-1}]\\) \u2705 Reshape \\(\\text{Reshape}(A_{m,n}) = A_{n,m}\\) \u2705 Identity matrix (eye) \\(\\text{The Identity matrix }{I_n}\\text{of size}{n} {x} {n}\\text{is defined as:} \\ \\ {I_{ij}} = \\bigg( \\frac{1 \\text{if} i = j}{0 \\text{if} i\\ne j}\\) \u2705 <p>Where: - \\(\\(A_{ij}\\)\\), \\(\\(B_{ij}\\)\\), and \\(\\(C_{ij}\\)\\) represent elements at the \\(\\(i\\)-th\\) row and \\(\\(j\\)-th\\) column of matrices \\(\\(A\\)\\), \\(\\(B\\)\\), and \\(\\(C\\)\\), respectively. - The matrices \\(\\(A\\)\\) and \\(\\(B\\)\\) must have the same dimensions for addition to be valid.</p> <ul> <li>Operation Derivative</li> </ul> Operation Derivative Formula Status Addition_backward \\(\\frac{\\partial C}{\\partial A} = I, \\quad \\frac{\\partial C}{\\partial B} = I\\) \u2705 Subtraction_backward \\(\\frac{\\partial C}{\\partial A} = I, \\quad \\frac{\\partial C}{\\partial B} = -I\\) \u2705 Maltiplication_backward \\(\\frac{\\partial C}{\\partial A} = B, \\quad \\frac{\\partial C}{\\partial B} = A\\) \u2705 Division_backward \\(\\frac{\\partial C}{\\partial A} = B, \\quad \\frac{\\partial C}{\\partial B} = A\\) \u2705 Dot_Product_backward \\(\\frac{\\partial C}{\\partial A} = I, \\quad \\frac{\\partial C}{\\partial B} = I\\) \u2705 Exponent_backward \\(\\frac{\\partial C}{\\partial X} = e^{x_{i,j}}\\) \u2705 Logarithm_backward \\(\\frac{\\partial C}{\\partial X} = \\frac{1}{X}\\) \u274c Power_backward \\(\\frac{\\partial C}{\\partial A} = B \\cdot A^{n-1}\\) \u2705 Sum_backward \\(\\frac{\\partial C}{\\partial X_i} = 1\\ \\  \\text{for each}\\ \\  {i}\\) \u2705 Transpose_backward Not applicable for individual elements but preserves structure. - Flatten_backward No derivative directly, but a 1-to-1 mapping between elements is maintained. - Reshape_backward No direct derivative as it doesn\u2019t involve computation. Used for data structure organization. - <ul> <li>Memory Management: Efficient use of malloc, calloc, memcpy, and memset for optimized memory handling.</li> </ul> Task Status Free Tensor \u2705 <ol> <li> <p>Automatic Differentiation</p> </li> <li> <p>Gradient Storage: Each tensor can store its gradient, initialized with calloc for zeroing the memory.</p> </li> </ol> Task Status grad \u2705 requires_grad \u2705 <ul> <li>Backward Propagation: Simple backpropagation framework to calculate gradients for model parameters.</li> </ul> Task Status Backward \u2705 <ul> <li>Operators for Gradient Tracking: Support for chaining operations to compute gradients through layers of the network.</li> </ul> Task Status prev \u2705 op \u2705 num_prev \u2705 <ol> <li> <p>Basic Neural Network Layers</p> </li> <li> <p>Linear (Dense) Layer: Implement a fully connected layer, allowing the network to learn transformations.</p> </li> </ol> Task Status Linear \u274c <ul> <li>Activation Functions: Include foundational activation functions (e.g., ReLU, Sigmoid, Tanh) with support for gradient calculations.</li> </ul> <p>i.  Activations</p> Task Formular Status ReLU \\(\\text{ReLU({x})} = \\bigg(\\frac{ {x}\\ \\text{if} {x}  \\geq\\ 0} {0  \\text{if} {x} &lt; 0}\\) \u2705 sigmoid \\(\\sigma(x) = \\frac{1}{1 + e^{-x}}\\) \u2705 tanh \\(\\text{tanh}(x) = \\frac{1 - e^{-2x}}{1 + e^{-2x}}\\) \u2705 softmax \\(\\text{Sofmax}{(x_i)} = \\frac{e^{x_i - \\text{max(x)}}}{\\sum_{j}{e^{x_j - \\text{max(x)}}}}\\) \u2705 LeakyReLU \\(\\text{LeakyReLU({x})} = \\bigg( \\frac{ {x }\\ \\text{ if } {x }  \\geq\\ 0} {\\alpha {x}  \\text{ if } {x } &lt; 0}\\) \u2705 mean \\(\\mu = \\frac{1}{n} \\sum_{i=1}^n x_i\\) \u2705 <ul> <li>Note: Softmax Numerical Stability<ul> <li>When  x  has large values,  \\(e^{x_i}\\)  may overflow. For numerical stability, PyTorch internally subtracts the maximum value from  \\(x\\)  before applying the softmax:</li> </ul> </li> </ul> <p>ii. Activations Derivative</p> Task Formular Status ReLU_backward \\(\\frac{\\partial}{\\partial{x}} = \\bigg( \\frac{ {1 }\\ \\text{ if } {x }  \\geq\\ 0} {0  \\text{ if } {x } \\le 0}\\) \u2705 sigmoid_backward \\(\\sigma{\\prime}(x) = \\sigma(x)(1 - \\sigma(x))\\) \u2705 tanh_backward \\(\\text{tanh}{\\prime}(x) = 1 - \\text{tanh}^2(x)\\) \u2705 softmax_backward \\(\\frac{\\partial}{\\partial{x_k}} = \\text{Softmax}{(x_k)}(1 - \\text{Softmax}{(x_k)})_{(diagonal: )} cross-element\\ requires\\ Jacobian\\) \u274c LeakyReLU_backward \\(\\frac{\\partial}{\\partial{x}} = \\bigg( \\frac{ {1 }\\ \\text{ if } {x }  \\geq\\ 0} {\\alpha  \\text{ if } {x } \\le 0}\\) \u2705 mean_backward \\(\\frac{\\partial{\\mu}}{\\partial{x_i}} = \\frac{1}{n}\\) \u2705 <ul> <li>Note: Derivative of Softmat.<ul> <li>The derivative depends on whether you\u2019re computing it for the same index \\(( i = j )\\) or different indices \\(( i \\neq j )\\).</li> <li>For a vector  \\(\\mathbf{s} = \\text{Softmax}(\\mathbf{x})\\) , the derivative is a matrix (Jacobian) given by:</li> <li>When  \\(i = j\\) : The derivative is  \\(s_i (1 - s_i)\\) , representing the change in  \\(s_i\\)  with respect to  \\(x_i\\) .</li> <li>When  \\(i \\neq j\\) : The derivative is  \\(-s_i s_j\\) , showing the interaction between different outputs of the softmax.</li> </ul> </li> </ul> \\[\\frac{\\partial s_i}{\\partial x_j} = \\begin{cases} s_i (1 - s_i), &amp; \\text{if } i = j \\\\ -s_i s_j, &amp; \\text{if } i \\neq j \\end{cases}\\] <ul> <li>Matrix Form of the Derivative (Jacobian).<ul> <li>The derivative can be represented as a Jacobian matrix for the softmax vector:</li> </ul> </li> </ul> \\[\\mathbf{J}(\\mathbf{s}) = \\text{diag}(\\mathbf{s}) - \\mathbf{s} \\mathbf{s}^T\\] <ul> <li> <p>Where:</p> <ul> <li>\\(\\text{diag}(\\mathbf{s})\\) : Diagonal matrix with  \\(s_i\\)  on the diagonal.</li> <li> <p>\\(\\mathbf{s} \\mathbf{s}^T\\) : Outer product of  \\(\\mathbf{s}\\)  with itself.</p> </li> <li> <p>Explicitly:</p> </li> </ul> </li> </ul> \\[\\mathbf{J}(\\mathbf{s}) = \\begin{bmatrix} s_1 (1 - s_1) &amp; -s_1 s_2 &amp; \\cdots &amp; -s_1 s_n \\\\ -s_2 s_1 &amp; s_2 (1 - s_2) &amp; \\cdots &amp; -s_2 s_n \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ -s_n s_1 &amp; -s_n s_2 &amp; \\cdots &amp; s_n (1 - s_n) \\end{bmatrix}\\] <ul> <li>Loss Functions: Basic loss functions like Mean Squared Error and Cross-Entropy to train simple models.</li> </ul>"},{"location":"Progress_and_Roadmap/#loss-functions","title":"Loss Functions","text":"Loss Function Type When to Use Advantages Disadvantages Status Mean Squared Error (MSE) Regression Regression with continuous targets Simple, differentiable Sensitive to outliers \u2705 Mean Absolute Error (MAE) Regression Regression with noisy data Less sensitive to outliers Less smooth gradient \u2705 Cross-Entropy Classification Binary or multi-class classification Works well with probabilistic models Sensitive to class imbalance \u274c Hinge Loss (SVM) Classification Support Vector Machines (SVM) Efficient for margin classifiers Not suitable for probabilistic tasks \u274c Huber Loss Regression Regression with outliers Robust to outliers, smooth Requires tuning of threshold \\(\\delta\\) \u274c KL Divergence Probabilistic Models Variational inference, generative models Compares probability distributions Asymmetric, computationally expensive \u274c NEGATIVE log likelyhood Classification - - - \u274c <p>i.    Mean Squared Error (MSE) Loss</p> <p>Formula:</p> <p>\\(\\text{MSE} = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)</p> <p>The derivative of MSE with respect to each prediction  \\(\\hat{y}_i\\)  is:</p> <p>\\(\\frac{\\partial \\text{MSE}}{\\partial \\hat{y}_i} = -\\frac{1}{n}(y_i - \\hat{y}_i)\\)</p> <p>Where: -    \\(y_i  = True value\\) -    \\(\\hat{y}_i  = Predicted value\\) -   \\(n  = Number of data points\\)</p> <p>How it Works:</p> <ul> <li>MSE calculates the average of the squared differences between predicted and true values. It penalizes large errors more significantly due to the squaring of the difference.</li> </ul> <p>ii.    Mean Absolute Error (MAE) Loss</p> <p>Formula:</p> <p>\\(\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\\)</p> <p>The derivative of MAE with respect to each prediction \\(\\hat{y}_i\\) is:</p> \\[ \\frac{\\partial \\text{MAE}}{\\partial \\hat{y}_i} =  \\begin{cases} -\\frac{1}{n}, &amp; \\text{if } \\hat{y}_i &gt; y_i \\\\ \\frac{1}{n}, &amp; \\text{if } \\hat{y}_i &lt; y_i \\end{cases} \\] <p>Where: -    \\(y_i  = True value\\) -    \\(\\hat{y}_i  = Predicted value\\) -   \\(n  = Number of data points\\)</p> <p>Handling Non-Differentiability at \\(y_i = \\hat{y}_i\\):</p> <ul> <li>At \\(y_i = \\hat{y}_i\\), the derivative is undefined because the slope of the absolute value changes abruptly. In practice:<ul> <li>For optimization algorithms, $0# or small gradient value is often used.</li> <li>Some frameworks introduce smooth approximations to \\(|x|\\) (e.g, Huber loss) to avoid the issue of non-differentiability.</li> </ul> </li> </ul> <p>How it Works:</p> <ul> <li>MAE computes the average of the absolute differences between predicted and true values. Unlike MSE, it does not square the differences, which makes it less sensitive to large errors.</li> </ul> <p>iii.    Cross-Entropy Loss</p> <p>Formula (for Binary Classification):</p> <p>\\(\\text{Binary Cross-Entropy} = - \\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)]\\)</p> <p>For Multi-Class Classification:</p> <p>\\(\\text{Categorical Cross-Entropy} = - \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{ic} \\log(\\hat{y}_{ic})\\)</p> <p>Where: -    \\(y_i  = True probability distribution\\) -    \\(\\hat{y}_i  = Predicted probability distribution\\) -    \\(C  = Number of classes\\) -    \\(y_{ic}  = 1 if the instance belongs to class  c , else 0\\) -    $\\hat{y}_{ic}  = Predicted probability for class  c $</p> <p>How it Works:</p> <ul> <li>Cross-entropy loss measures the difference between two probability distributions: the true label distribution and the predicted probability distribution. It is widely used in classification tasks.</li> </ul> <p>iv.    Hinge Loss (SVM Loss)</p> <p>Formula:</p> <p>\\(\\text{Hinge Loss} = \\sum_{i=1}^{n} \\max(0, 1 - y_i \\hat{y}_i)\\)</p> <p>Where: -    \\(y_i  = True label (+1 or -1)\\) -    \\(\\hat{y}_i  = Predicted score (not probability)\\)</p> <p>How it Works:</p> <ul> <li>Hinge loss is used in Support Vector Machines (SVM) and other classification tasks. It penalizes predictions that are on the wrong side of the decision boundary and doesn\u2019t penalize correctly classified points as long as they are on the correct side of the margin.</li> </ul> <p>v.    Huber Loss</p> <p>Formula:</p> \\[\\text{Huber}(\\delta) = \\begin{cases} \\frac{1}{2}(y_i - \\hat{y}_i)^2, &amp; \\text{for } |y_i - \\hat{y}_i| \\leq \\delta \\\\ \\delta |y_i - \\hat{y}_i| - \\frac{1}{2} \\delta^2, &amp; \\text{otherwise} \\end{cases}\\] <p>Where: -    \\(\\delta\\)  is a threshold that determines the transition from quadratic to linear loss.</p> <p>How it Works:</p> <ul> <li>Huber loss combines both MSE and MAE. It behaves like MSE for small errors (i.e., when the absolute error is less than  \\delta ) and like MAE for large errors. This makes it less sensitive to outliers compared to MSE while still being differentiable.</li> </ul> <p>vi.    Kullback-Leibler Divergence (KL Divergence)</p> <p>Formula:</p> <p>\\(\\text{KL Divergence} = \\sum_{i=1}^{n} p_i \\log\\left(\\frac{p_i}{q_i}\\right)\\)</p> <p>Where: -    \\(p_i  = True distribution (e.g., true labels)\\) -    \\(q_i  = Predicted distribution\\)</p> <p>How it Works:</p> <ul> <li> <p>\\(KL\\) divergence measures the difference between two probability distributions. It is asymmetric, meaning  \\(\\text{KL}(p \\parallel q) \\neq \\text{KL}(q \\parallel p)\\) .</p> </li> <li> <p>Optimization Algorithms</p> </li> <li> <p>Gradient Descent: Implement vanilla gradient descent for updating weights.</p> </li> </ul> Task Status step optimizer \u274c <ul> <li>Extensions: Planned support for optimizations like Stochastic Gradient Descent (SGD) and other optimizers (e.g., Adam) as the library progresses.</li> </ul>"},{"location":"Progress_and_Roadmap/#optimizers","title":"Optimizers","text":"Task Status ADAM \u274c SGD \u274c RMS PROP \u274c ADADELTA \u274c ADAGRAD \u274c ADAMW \u274c <ol> <li> <p>Training and Evaluation Loop</p> </li> <li> <p>Forward and Backward Passes: Execution of forward pass and automatic differentiation for backpropagation.</p> </li> <li> <p>Metrics Tracking: Calculate and log accuracy or loss during training.</p> </li> <li> <p>Progress Display: Basic progress bar for training epochs and mini-batches.</p> </li> </ol>"},{"location":"Progress_and_Roadmap/#layers","title":"Layers","text":"Task Status SEQUENTIAL \u274c LINEAR \u274c DROPOUT \u274c CONV2D \u274c CONV3D \u274c MAXPOOL2D \u274c MAXPOOL3D \u274c"},{"location":"Progress_and_Roadmap/#future-milestones","title":"Future Milestones","text":"<ol> <li> <p>Additional Neural Network Layers</p> </li> <li> <p>Convolutional Layers: Add convolution layers for basic image-processing tasks.</p> </li> <li> <p>Pooling Layers: Max and average pooling layers for reducing spatial dimensions.</p> </li> <li> <p>Expanded Tensor Operations</p> </li> <li> <p>Broadcasting: Support for basic broadcasting to handle mismatched tensor shapes.</p> </li> <li> <p>Advanced Math Operations: Include more operations (e.g., exponentiation, logarithms) for increased model complexity.</p> </li> <li> <p>GPU/Hardware Support</p> </li> <li> <p>OpenCL/CUDA Integration: Explore integration with OpenCL or CUDA to leverage GPUs for faster computation.</p> </li> <li> <p>SIMD Optimizations: Use SIMD instructions for faster CPU-based tensor operations.</p> </li> <li> <p>Serialization and Model Exporting</p> </li> <li> <p>Model Saving and Loading: Save model weights and parameters for reproducibility and deployment.</p> </li> <li> <p>ONNX Export: Basic support for ONNX format export, allowing compatibility with other deep learning frameworks.</p> </li> <li> <p>Python Bindings</p> </li> <li> <p>Python API: Create a minimal Python API for easy usage and debugging, making it accessible for Python-based experimentation.</p> </li> </ol>"},{"location":"Documentation/documentation/","title":"Documentation","text":"<p>nan: Something between tinygrad, PyTorch, karpathy/micrograd, Aten and XLA. Maintained by nano corp.</p>"},{"location":"Documentation/documentation/#progress-and-roadmap-home-page","title":"Progress and Roadmap | Home Page","text":"nan Documentation <p>Welcome to the nan documentation. This page is for those who are really want to make a change in AI, if it is you, you are welcome.</p> <p>To get this library in your local machine, you can download it from GitHub. See...</p> <pre><code>git clone https://github.com/oderoi/nanoTorch.git \n</code></pre> <p>This library is created in C and it has no frontend yet, so you will use C to use it.</p>"},{"location":"Documentation/documentation/#nan-usage","title":"nan Usage","text":"<p>The one thing you will need to import is torch.h header.</p> <pre><code>#include  \"torch.h\"\n</code></pre> <p>In C we don't use <code>import</code> like in Python, we use <code>#include</code>.</p> <p>Amaizing enough <code>torch.h</code> header is the library in itself and it is just a single file. It contain functions to help you perform math operations for machine leaning and automatic differentiation capabilities.</p> <p>For now nan library operations are not lazy but Backpropagation is lazy, meaning it won't do backward pass operations until you realize.</p> <ul> <li>nan has AOT support, so it run very close to hardware to achieve high performance, high speed and it give's you more cotrol.</li> <li>nan support CPU only for now. But it will support GPUs and TPUs. </li> </ul>"},{"location":"Documentation/documentation/#nan-stack","title":"nan Stack","text":"Library Core Language Kernel Layer Assembly/Hardware Layer PyTorch Python + C++ ATen SIMD/AVX/CUDA/TPU instructions TensorFlow Python + C++ XLA Kernels LLVM-generated assembly, GPU, TPU TinyGrad Python Numpy/Custom Ops CPU SIMD, CUDA for GPU Nan C nan nan <ul> <li>nan stack combines Kernel Layer and Assembly/Hardware Layer to make it more simple to improve, read and improve for anyone interested.</li> <li>nan Assembly/Hardware Layer only supports CPU for now.</li> </ul>"},{"location":"Documentation/documentation/#quick-start","title":"Quick Start","text":""},{"location":"Documentation/quick_start/","title":"Quick Start","text":"<p>nan: Something between tinygrad, PyTorch, karpathy/micrograd, Aten and XLA. Maintained by nano corp.</p>"},{"location":"Documentation/quick_start/#documentatio-home-page","title":"Documentatio | Home Page","text":""},{"location":"Documentation/quick_start/#quick-start-guide","title":"Quick Start Guide","text":"<p>This guide assumes you have no prior knowledge of C, C++, PyTorch or any other language or deelearning framework.</p> <p>First you have to download nan library from GitHub.</p> <pre><code>git clone https://github.com/oderoi/nanoTorch.git\n</code></pre> <p>Then create a working directory in your machine/Laptop folder, open nanoTorch and copy <code>torch.h</code> and pest it in your folder you created. Then create a <code>new_file</code> that you will use to code your project.</p> <p>Then open the <code>new_file</code> in your fevorite code editor. and start to code.</p> <p>Start by importing the library.</p> <pre><code>#inlude \"torch.h\"\n</code></pre> <p>Now you are set.</p>"},{"location":"Documentation/quick_start/#tensor","title":"Tensor","text":"<p>Tensors are the base data structure in nan. They are like multi-dimensional array of a specific data type. All higher-level operations in nan operate on these tensors.</p> <p>Tensor can be created from existing data.</p> <pre><code>Tensor * t1 = tensor((float[]){1, 2, 3, 4, 5, 6}, FLOAT32, (int[]){2, 3}, 2, true);\n</code></pre> <p>So you might being asking yourself what the heck is that, don't sweet , let's see what the hell is that, and will start by looking one part after the other.</p> <ul> <li><code>Tensor * t1</code>: this is the variable definition where.<ul> <li><code>Tensor *</code>: telling our program that this is the <code>Tensor</code> type multidimensional array like.</li> <li><code>t1</code>: is the name of our data, you can choose to use any name you like.</li> </ul> </li> <li><code>tensor()</code>: is the function that helping us to hold together all the important information about out array, like data, data type,data dimension, data rank and requires grad.<ul> <li><code>(float[]){1, 2, 3, 4, 5, 6}</code>:this is the data itself that <code>Tensor * t1</code> carries and <code>(float[])</code> is the data type of the array, while <code>{1, 2, 3, 4, 5, 6}</code> is the arry itself.</li> <li><code>FLOAT32</code>: this is the Tensor data type, which is suppossed to be the same as <code>(float[])</code>.</li> <li><code>(int[]){2, 3}</code>: is the array dimension. As well here <code>(int[])</code> is the data type of the dimension array ( and Yes, I just say array again, because array data and dimension are both representade using array) and <code>{2, 3}</code> is the dimension itself.</li> <li><code>2</code>: this number represent rank of our Tensor, simply put, if dimesion is of two dimensions like <code>{2, 3}</code> then rank will be 2 aswell and if dimension if just one dimension like <code>{3}</code> then the rank will be <code>1</code>.</li> <li><code>true</code>: this boolean tell us that this <code>Tensor</code> will carry gradients of it's variable, during back propagation. So it might be <code>true</code> or <code>false</code>, depending on weither you want to calculate gradiant correspond of the <code>Tensor</code>.</li> </ul> </li> </ul>"}]}