<!-- <h1 align='center'><b>nano</b></h1> -->

<div align="center">

<picture>
  <source media="(prefers-color-scheme: light)" srcset="/imgs/nan/16.svg">
  <img alt="tiny corp logo" src="/imgs/nan/nan.svg" width="50%" height="50%">
</picture>

nano: Something between [tinygrad](https://tinygrad.org/), [PyTorch](https://github.com/pytorch/pytorch) , [karpathy/micrograd](https://github.com/karpathy/micrograd) and [XLA](https://openxla.org/xla). Maintained by [nano corp](https://github.com/oderoi/nanoTorch/tree/main).

<h3>

[Progress and Roadmap](Progress_and_Roadmap.md) | [Documentation](Documentation/documentation.md)

</h3>

<!-- [![GitHub Repo stars](https://img.shields.io/github/stars/tinygrad/tinygrad)](https://github.com/tinygrad/tinygrad/stargazers)
[![Unit Tests](https://github.com/tinygrad/tinygrad/actions/workflows/test.yml/badge.svg)](https://github.com/tinygrad/tinygrad/actions/workflows/test.yml)
[![Discord](https://img.shields.io/discord/1068976834382925865)](https://discord.gg/ZjZadyC7PK) -->

</div>

---

<!-- <h1 align="center">
  <img src="imgs/nan/nan.svg" alt="Dainemo Logo" width="400" height="250"/>
</h1> -->
<p align='center'>
    A PyTorch like AI Engine from scratch in C programming language
</p>
<!-- <p align="center">
  <img src="imgs/cerebrix.png" alt="Dainemo Logo" width="150"/>
</p> -->

<p>
Nano is a lightweight, minimalistic high-performance numerical computing library for deep learning written in pure C, designed to bring essential neural network functionalities to low-resource environments. Inspired by projects like minigrad, tinygrad, XLA and PyTorch, Nano aims to provide a foundational toolkit for machine learning enthusiasts, embedded developers, and researchers who want to experiment with deep learning concepts in an efficient, resource-conscious manner.
</p>

#### Key Features

-  Lightweight Design: Focused on simplicity, Nano provides core deep learning operations without heavy dependencies.
-  Pure C Implementation: Built entirely in C, Nano is designed to be portable and optimized for low-level manipulation.
-  Gradient Calculation: Includes basic automatic differentiation to support backpropagation for training models.
-  Flexible Tensor Operations: Supports fundamental tensor operations required for deep learning.
-  Modular Architecture: Easy to extend or modify, allowing you to explore and experiment with new layers, optimizers, and more.

#### Who is This For?

NanoTorch is perfect for those looking to:
-  Understand the inner workings of a deep learning library from the ground up.
-  Run simple neural networks in resource-limited environments.
-  Prototype and test custom ML operations in C.

#### Getting Started

This repository includes setup instructions, usage examples, and documentation to help you dive into developing with Nano. Explore the source code to understand how core deep learning concepts like tensor operations and automatic differentiation are implemented.

#### Contributing

Nano is open for contributions! Whether youâ€™re fixing bugs, adding new features, or experimenting with optimizations, we welcome your input.